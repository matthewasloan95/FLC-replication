{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper can be found here: [https://www.gperezs.com/papers/bppa.pdf](https://www.gperezs.com/papers/bppa.pdf) and their CVPR 2019 workshop publication can be found here [https://biomedicalcomputervision.uniandes.edu.co/publications/finding-four-leaf-clovers-a-benchmark-for-fine-grained-object-localization/](https://biomedicalcomputervision.uniandes.edu.co/publications/finding-four-leaf-clovers-a-benchmark-for-fine-grained-object-localization/)\n",
    "\n",
    "Given over 100,000 images and many types of annotations, instane, semantic etc... how do we get this ready for use?   \n",
    "Here is a file tree of the [FLC data](https://drive.google.com/file/d/1fq6ZeVg2-CjRtKgcBcnKy9jLfUIabfe8/view?usp=sharing)   \n",
    "```\n",
    "FLC2019 % tree -C -r -I '*.jpg|*.png|*.mat'   \n",
    ".\n",
    "├── trainval\n",
    "│   ├── coco_annotations\n",
    "│   │   ├── leaves_trainval_pos.json\n",
    "│   │   ├── leaves_trainval_negs.json\n",
    "│   │   ├── instances_trainval_pos.json\n",
    "│   │   ├── instances_trainval_negs.json\n",
    "│   │   └── instances_trainval_hard_pos.json\n",
    "│   ├── SegmentationClass\n",
    "│   ├── JPEGImages_pos\n",
    "│   ├── JPEGImages\n",
    "│   └── BorderClass\n",
    "├── test\n",
    "│   ├── gt_mats_pos\n",
    "│   ├── gt_mats\n",
    "│   │   └── gt_mats_pos\n",
    "│   ├── coco_annotations\n",
    "│   │   ├── leaves_test_pos.json\n",
    "│   │   ├── leaves_test_negs.json\n",
    "│   │   ├── instances_test_pos.json\n",
    "│   │   ├── instances_test_negs.json\n",
    "│   │   ├── instances_test_hard_pos.json\n",
    "│   │   └── instances_test_all.json\n",
    "│   ├── SegmentationClass\n",
    "│   ├── JPEGImages_pos\n",
    "│   ├── JPEGImages_neg\n",
    "│   ├── JPEGImages\n",
    "│   ├── BorderClass_pos\n",
    "│   ├── BorderClass_alejo\n",
    "│   └── BorderClass\n",
    "│       └── BorderClass_pos\n",
    "└── create_contours.py\n",
    "\n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as data we will be using, we will not be using the .mat files or the BorderClass files.   \n",
    "Here is some more information:   \n",
    "* In the **trainval**/JPEGImages_pos dir, we have 1000 jpg files totalling 1.63GB. These are images *with* four-leaf clovers   \n",
    "* In the **trainval**/JPEGImages dir, we have 52,638 jpg files totalling 23.8GB. These are images *without* four-leaf clovers as well as the same 1000 images *with* four-leaf clovers   \n",
    "  \n",
    "-----\n",
    "\n",
    "*   In the **test**/JPEGImages_pos dir, we have 500 jpg files totalling 888.8MB. These are images *with* four-leaf clovers  \n",
    "*   In the **test**/JPEGImages_neg dir, we have 51,671 jpg files totalling 22.2GB. These are images *without* four-leaf clovers  \n",
    "*   Additionally, we have the  **test**/JPEGImages dir which combines both the pos and neg images into a single dir   \n",
    "  \n",
    "-----   \n",
    "   \n",
    "According to their paper:\n",
    "\n",
    "| General statistics         | Trainval set | Test set |\n",
    "|----------------------------|--------------|----------|\n",
    "| Total positive images      | 1,000        | 500      |\n",
    "| Total negative images      | 51,637       | 51,670   |\n",
    "| Total images               | 52,637       | 52,170   |\n",
    "| 4-leaf clover instances    | 1,412        | 739      |\n",
    "| 4-leaf clover leaves       | 5,858        | 3,094    |\n",
    "| 4-leaf clover pixels       | 0.0445%      | 0.0588%  |\n",
    "| 4-leaf clover boundary pxls| 0.0026%      | 0.0030%  |\n",
    "\n",
    "Both the trainval and test dirs include a coco_annotations dir, I will be using the *instances_trainval_hard_pos.json* and *instances_test_hard_pos.json* - This is for the sake of my limitation of training time and compute resources. These are standard coco bbox and segmentation annotations for the pos images. They include both three-leaf clovers and four-leaf clovers annotated in all 1500 trainval/test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What results are we trying to replicate?   \n",
    "\n",
    "Object Detection:   \n",
    "Semantic Segmentation:   \n",
    "Instance Segmentation:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get some basic vars out of the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image dirs\n",
    "trainval_pos_img_dir = '/Users/mattsloan/Downloads/FLC2019/trainval/JPEGImages_pos'\n",
    "test_pos_img_dir = '/Users/mattsloan/Downloads/FLC2019/test/JPEGImages_pos'\n",
    "\n",
    "# coco annotation files\n",
    "trainval_hard_ann = '/Users/mattsloan/Downloads/FLC2019/trainval/coco_annotations/instances_trainval_hard_pos.json'\n",
    "test_hard_ann = '/Users/mattsloan/Downloads/FLC2019/test/coco_annotations/instances_test_hard_pos.json'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
